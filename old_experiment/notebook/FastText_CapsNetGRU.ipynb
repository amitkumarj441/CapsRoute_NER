{"cells":[{"metadata":{"trusted":true,"_uuid":"7044edbbe33842143e5caaf20a059558a23b6abf"},"cell_type":"code","source":"import keras\nprint(keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89386040c774c2288b9b4e4e7011c971a813676c"},"cell_type":"code","source":"from keras.utils.vis_utils import plot_model as plot","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, PReLU\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/train.tsv', sep=\"\\t\")\ntest = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/test.tsv', sep=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bf18c26da60878af23557ba69bd06ef7dbb2156d"},"cell_type":"code","source":"tk = Tokenizer(lower = True, filters='')\nfull_text = list(train['Phrase'].values) + list(test['Phrase'].values)\ntk.fit_on_texts(full_text)\ntrain_tokenized = tk.texts_to_sequences(train['Phrase'])\ntest_tokenized = tk.texts_to_sequences(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8e27f3170466f056f0ec6057eadd89c5a004a621"},"cell_type":"code","source":"max_len = 50\nX_train = pad_sequences(train_tokenized, maxlen = max_len)\nX_test = pad_sequences(test_tokenized, maxlen = max_len)\n\nembedding_path = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\" #fasttext crawl 300d \n\nembed_size = 300\nmax_features = 2000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3127e9f08d2d9eb4274be681c7ffbf52d4e57c79"},"cell_type":"code","source":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n\nword_index = tk.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words + 1, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f8c2742cd2ee5da26365833f011209c53f6db92f"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ny = train['Sentiment']\nohe = OneHotEncoder(sparse=False)\ny_ohe = ohe.fit_transform(y.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"efd984ee045d11654219ee12d5baa85c4ca159ad"},"cell_type":"code","source":"file_path = \"best_model.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"941bef9248248874097fc2531de1f5e4f1faa4a6"},"cell_type":"code","source":"def squash(x, axis=-1):\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n    scale = K.sqrt(s_squared_norm + K.epsilon())\n    return x / scale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bdd58b5df2fdaa7102d2b678185299d6cd695254"},"cell_type":"code","source":"# A Capsule Implement with Pure Keras\nclass Capsule(Layer):\n    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n                 activation='default', **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_size = kernel_size\n        self.share_weights = share_weights\n        if activation == 'default':\n            self.activation = squash\n        else:\n            self.activation = Activation(activation)\n\n    def build(self, input_shape):\n        super(Capsule, self).build(input_shape)\n        input_dim_capsule = input_shape[-1]\n        if self.share_weights:\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(1, input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     # shape=self.kernel_size,\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n        else:\n            input_num_capsule = input_shape[-2]\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(input_num_capsule,\n                                            input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n\n    def call(self, u_vecs):\n        if self.share_weights:\n            u_hat_vecs = K.conv1d(u_vecs, self.W)\n        else:\n            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n\n        batch_size = K.shape(u_vecs)[0]\n        input_num_capsule = K.shape(u_vecs)[1]\n        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n                                            self.num_capsule, self.dim_capsule))\n        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n\n        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n        for i in range(self.routings):\n            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n            c = K.softmax(b)\n            c = K.permute_dimensions(c, (0, 2, 1))\n            b = K.permute_dimensions(b, (0, 2, 1))\n            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n            if i < self.routings - 1:\n                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (None, self.num_capsule, self.dim_capsule)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"305c2586441f5577f3ea9c003906242aff49be0f"},"cell_type":"code","source":"def get_model_capsule(gru_spec=(128, 0), gru_dropout=5e-5, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n    inp = Input(shape = (max_len,))\n    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n    x1 = SpatialDropout1D(dr)(x)\n\n    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n    x_words = PReLU()(x_gru)\n    x_words = Capsule(num_capsule=5, dim_capsule=16, routings=5, share_weights=True)(x_words)\n    x_words = Flatten()(x_words)\n    x_words = Dropout(0.15)(x_words)\n\n    \n    x = Dropout(0.1)(Dense(64,activation='relu') (x_words))\n    pred = Dense(5, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = pred)\n    model.summary()\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n                        verbose = 1, callbacks = [check_point, early_stop])\n\n    return model\n    try:\n        plot(model, to_file = 'capsnet_gru.png', how_shapes=True, show_layer_names=True)\n    except ImportError:\n        print('It seems like the dependencies for drawing the model (pydot, graphviz) are not installed')  \n  \nmodel_capsule = get_model_capsule(lr = 1e-3, units = 128, dr = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4630196de0b27c62b93d6ba2ca94583b16cfc88b"},"cell_type":"code","source":"pred = model_capsule.predict(X_test, batch_size = 1024, verbose = 1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}